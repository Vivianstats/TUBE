create_classify_fun = function(xtrain, ytrain, method, xnew, cost, ...){
fun = function(xtrain, ytrain, method, cost, ...){
data_str = stratification(xtrain, ytrain, cost)
prob = classify_base(xtrain = data_str$x, ytrain = data_str$y, xnew = xleave,
xnew, method, ...)
return(prob)
}
return(fun)
}
create_classify_fun = function(method, ...){
fun = function(xtrain, ytrain, method, cost, ...){
data_str = stratification(xtrain, ytrain, cost)
prob = classify_base(xtrain = data_str$x, ytrain = data_str$y, xnew = xleave,
xnew, method, ...)
return(prob)
}
return(fun)
}
classify_fun = create_classify_fun(method, cost, ...)
classify_fun = create_classify_fun(method)
method
classify_fun = create_classify_fun(method = "LR")
classify_fun
create_classify_fun = function(method, ...){
fun = function(xtrain, ytrain, method = method, cost, ...){
data_str = stratification(xtrain, ytrain, cost)
prob = classify_base(xtrain = data_str$x, ytrain = data_str$y, xnew = xleave,
xnew, method, ...)
return(prob)
}
return(fun)
}
classify_fun = create_classify_fun(method = "LR")
classify_fun
create_classify_fun = function(method, ...){
fun = function(xtrain, ytrain, method = method, cost, ...){
data_str = stratification(xtrain, ytrain, cost)
prob = classify_base(xtrain = data_str$x, ytrain = data_str$y, xnew = xleave,
xnew, method = method, ...)
return(prob)
}
return(fun)
}
classify_fun = create_classify_fun(method = "LR")
classify_fun
classify_fun = create_classify_fun(method = "LR")()
create_classify_fun = function(method, ...){
fun = function(xtrain, ytrain, method, cost, ...){
data_str = stratification(xtrain, ytrain, cost)
prob = classify_base(xtrain = data_str$x, ytrain = data_str$y, xnew = xleave,
xnew, method, ...)
return(prob)
}
return(fun)
}
classify_fun = create_classify_fun(method = "LR")
classify_fun
create_classify_fun = function(method, ...){
fun = function(xtrain, ytrain, cost, ...){
data_str = stratification(xtrain, ytrain, cost)
prob = classify_base(xtrain = data_str$x, ytrain = data_str$y, xnew = xleave,
xnew, method, ...)
return(prob)
}
return(fun)
}
classify_fun = create_classify_fun(method = "LR")
classify_fun
create_classify_fun = function(method1, ...){
fun = function(xtrain, ytrain, cost, ...){
data_str = stratification(xtrain, ytrain, cost)
prob = classify_base(xtrain = data_str$x, ytrain = data_str$y, xnew = xleave,
xnew, method=method1, ...)
return(prob)
}
return(fun)
}
classify_fun = create_classify_fun(method1 = "LR")
classify_fun
create_classify_fun = function(method2, ...){
fun = function(method1 = method2, xtrain, ytrain, cost, ...){
print(method1)
data_str = stratification(xtrain, ytrain, cost)
prob = classify_base(xtrain = data_str$x, ytrain = data_str$y, xnew = xleave,
xnew, method=method1, ...)
return(prob)
}
return(fun)
}
classify_fun = create_classify_fun(method2 = "LR")
classify_fun
create_classify_fun = function(method2, ...){
print(method2)
fun = function(method1 = method2, xtrain, ytrain, cost, ...){
print(method1)
data_str = stratification(xtrain, ytrain, cost)
prob = classify_base(xtrain = data_str$x, ytrain = data_str$y, xnew = xleave,
xnew, method=method1, ...)
return(prob)
}
return(fun)
}
classify_fun = create_classify_fun(method2 = "LR")
make.power <- function(n) {
pow <- function(x) {
x^n
}
pow
}
make.power
n = 100
f1 = make.power(2)
f1
f1(2)
classify_fun = function(xtrain, ytrain, cost, xnew, method = "LR", ...){
data_str = stratification(xtrain, ytrain, cost)
score = classify_base(xtrain = data_str$x, ytrain = data_str$y, xnew = xleave,
xnew, method, ...)
return(score)
}
classify_fun
source("~/Dropbox/Rpkgs-dev/TUBE_dev/TUBE/R/classification.R")
source("~/Dropbox/Rpkgs-dev/TUBE_dev/TUBE/R/gen_data.R")
source("~/Dropbox/Rpkgs-dev/TUBE_dev/TUBE/R/tube.R")
classify_fun = function(xtrain, ytrain, cost, xnew, method = "LR", ...){
data_str = stratification(xtrain, ytrain, cost)
score = classify_base(xtrain = data_str$x, ytrain = data_str$y, xnew = xleave,
xnew, method, ...)
return(score)
}
data_obs = gen_data(model="gaussian", n=1000, d = 10, pi=0.5)
library(MASS)
library(glmnet) # glmnet
library(mvtnorm) # rmvt
install.packages("mvtnorm")
install.packages("glmnet")
data_obs = gen_data(model="gaussian", n=1000, d = 10, pi=0.5)
data = gen_data(model="gaussian", n=1000, d = 10, pi=0.5)
TUBEc(data, classify_fun, alpha = 0.05, delta = 0.1,
t_cs = 0.5, nleave = NULL,cost = seq(0.1, 0.99, 0.01))
alpha = 0.05
delta = 0.1
t_cs = 0.5
cost = seq(0.1, 0.99, 0.01)
nleave = NULL
XX = data$x
YY = data$y
x_c0 = XX[YY == 0, ]
x_c1 = XX[YY == 1, ]
if(is.null(nleave)){
nleave = floor(sum(YY == 0)/2)
}
ind_leave = sample(1:nrow(x_c0), nleave, replace = FALSE)
xleave = x_c0[ind_leave, ]
xtrain = rbind(x_c0[-ind_leave, ], x_c1)
ytrain = c(rep(0, nrow(x_c0)-nleave), rep(1, nrow(x_c1)))
c = 1
wcost = cost[c]
alp_emp = 1
wcost
# data_str = stratification(xtrain, ytrain, wcost)
# prob1 = classify_base(xtrain = data_str$x, ytrain = data_str$y, xnew = xleave,
#                       method = class_method, lambda = 0.01)
prob1 = classify_fun(xtrain, ytrain, cost = wcost, xnew = xleave)
classify_fun
cost = wcost
xnew = xleave
data_str = stratification(xtrain, ytrain, cost)
classify_fun = function(xtrain, ytrain, cost, xnew, method = "LR", ...){
data_str = stratification(xtrain, ytrain, cost)
print(method)
score = classify_base(xtrain = data_str$x, ytrain = data_str$y, xnew = xleave,
xnew, method, ...)
return(score)
}
TUBEc(data, classify_fun, alpha = 0.05, delta = 0.1,
t_cs = 0.5, nleave = NULL,cost = seq(0.1, 0.99, 0.01))
classify_fun = function(xtrain, ytrain, cost, xnew, method = "LR", ...){
data_str = stratification(xtrain, ytrain, cost)
print(method)
score = classify_base(xtrain = data_str$x, ytrain = data_str$y, xnew = xleave,
method, ...)
return(score)
}
data = gen_data(model="gaussian", n=1000, d = 10, pi=0.5)
TUBEc(data, classify_fun, alpha = 0.05, delta = 0.1,
t_cs = 0.5, nleave = NULL,cost = seq(0.1, 0.99, 0.01))
dtrain = data.frame(ytrain = ytrain, xtrain)
obj = glm(ytrain~., family=binomial(link='logit'), data = dtrain, ...)
obj = glm(ytrain~., family=binomial(link='logit'), data = dtrain)
obj$fitted.values
tp1 = predict(obj, type = "response")
tp2 = predict(obj, data.frame(xtrain), type = "response")
sum(tp1 != tp2)
source("~/Dropbox/Rpkgs-dev/TUBE_dev/TUBE/R/classification.R")
source("~/Dropbox/Rpkgs-dev/TUBE_dev/TUBE/R/gen_data.R")
source("~/Dropbox/Rpkgs-dev/TUBE_dev/TUBE/R/tube.R")
classify_fun = function(xtrain, ytrain, cost, xnew, method = "LR", ...){
data_str = stratification(xtrain, ytrain, cost)
score = classify_base(xtrain = data_str$x, ytrain = data_str$y, xnew = xleave,
method, ...)
return(score)
}
data = gen_data(model="gaussian", n=1000, d = 10, pi=0.5)
res_tubec = TUBEc(data, classify_fun, alpha = 0.05, delta = 0.1,
t_cs = 0.5, nleave = NULL,cost = seq(0.1, 0.99, 0.01))
res_tube = TUBE(data, classify_fun, alpha = 0.05, delta = 0.1,
t_cs = 0.5, nleave = NULL,cost = seq(0.1, 0.99, 0.01))
source('~/Dropbox/Rpkgs-dev/TUBE_dev/TUBE/R/tube.R')
res_tube = TUBE(data, classify_fun, alpha = 0.05, delta = 0.1,
t_cs = 0.5, nleave = NULL,cost = seq(0.1, 0.99, 0.01))
source('~/Dropbox/Rpkgs-dev/TUBE_dev/TUBE/R/tube.R')
res_tube = TUBE(data, classify_fun, alpha = 0.05, delta = 0.1,
t_cs = 0.5, nleave = NULL,cost = seq(0.1, 0.99, 0.01))
warnings()
source('~/Dropbox/Rpkgs-dev/TUBE_dev/TUBE/R/tube.R')
res_tube = TUBE(data, classify_fun, alpha = 0.05, delta = 0.1,
t_cs = 0.5, nleave = NULL,cost = seq(0.1, 0.99, 0.01))
warnings()
xobs = data$x
yobs = data$y
if(is.null(nleave)){
nleave = floor(sum(yobs == 0)/2)
}
c = 1
wcost = cost[c]
alp_emp = 1
if(wcost < max(cost)){
c = c+1; wcost = cost[c]
}else{break}
wcost
wcost < max(cost)
prob_train = classify_fun(xobs, yobs, cost = wcost, xnew = NULL)
est_all_emp = sum(prob_train > t_cs & yobs == 0, na.rm = TRUE)/sum(!is.na(prob_train))
length(prob_train)
dim(xobs)
summary(prob_train)
prob_train[1:4]
xtrain = xobs
ytrain = yobs
data_str = stratification(xtrain, ytrain, cost)
xtrain = data_str$x
ytrain = data_str$y
classify_fun = function(xtrain, ytrain, cost, xnew, method = "LR", ...){
data_str = stratification(xtrain, ytrain, cost)
score = classify_base(xtrain = data_str$x, ytrain = data_str$y, xnew,
method, ...)
return(score)
}
data = gen_data(model="gaussian", n=1000, d = 10, pi=0.5)
res_tubec = TUBEc(data, classify_fun, alpha = 0.05, delta = 0.1,
t_cs = 0.5, nleave = NULL,cost = seq(0.1, 0.99, 0.01))
res_tube = TUBE(data, classify_fun, alpha = 0.05, delta = 0.1,
t_cs = 0.5, nleave = NULL,cost = seq(0.1, 0.99, 0.01))
warnings()
res_tubec$c0
xobs = data$x
yobs = data$y
if(is.null(nleave)){
nleave = floor(sum(yobs == 0)/2)
}
c = 1
wcost = 0.1
prob_train = classify_fun(xobs, yobs, cost = wcost, xnew = NULL)
length(prob_train)
dim(xobs)
prob_train = classify_fun(xobs, yobs, cost = wcost, xnew = NULL)
length(prob_train)
classify_fun
source('~/Dropbox/Rpkgs-dev/TUBE_dev/TUBE/R/tube.R')
data = gen_data(model="gaussian", n=1000, d = 10, pi=0.5)
res_tubec = TUBEc(data, classify_fun, alpha = 0.05, delta = 0.1,
t_cs = 0.5, nleave = NULL, cost = seq(0.1, 0.99, 0.01))
res_tubec$c0
length(res_tubec$yhat)
res_tube = TUBE(data, classify_fun, alpha = 0.05, delta = 0.1,
t_cs = 0.5, nleave = NULL, cost = seq(0.1, 0.99, 0.01))
res_tube$c0
length(res_tube$yhat)
data = gen_data(model="gaussian", n=1000, d = 30, pi=0.5)
res_tubec = TUBEc(data, classify_fun, alpha = 0.05, delta = 0.1,
t_cs = 0.5, nleave = NULL, cost = seq(0.1, 0.99, 0.01))
res_tubec$c0
length(res_tubec$yhat)
data = gen_data(model="gaussian", n=1000, d = 30, pi=0.5)
res_tubec = TUBEc(data, classify_fun, alpha = 0.1, delta = 0.1,
t_cs = 0.5, nleave = NULL, cost = seq(0.1, 0.99, 0.01))
res_tubec$c0
length(res_tubec$yhat)
res_tube = TUBE(data, classify_fun, alpha = 0.1, delta = 0.1,
t_cs = 0.5, nleave = NULL, cost = seq(0.1, 0.99, 0.01))
res_tube$c0
length(res_tube$yhat)
data = gen_data(model="t", n=1000, d = 30, pi=0.5)
library(MASS)
library(glmnet) # glmnet
library(mvtnorm) # rmvt
data = gen_data(model="t", n=1000, d = 30, pi=0.5)
res_tubec = TUBEc(data, classify_fun, alpha = 0.1, delta = 0.1,
t_cs = 0.5, nleave = NULL, cost = seq(0.1, 0.99, 0.01))
res_tubec$c0
length(res_tubec$yhat)
res_tube = TUBE(data, classify_fun, alpha = 0.1, delta = 0.1,
t_cs = 0.5, nleave = NULL, cost = seq(0.1, 0.99, 0.01))
res_tube$c0
length(res_tube$yhat)
install.packages("randomForest")
install.packages("xgboost")
install.packages("naivebayes")
library(randomForest)
library(xgboost)
usethis::use_github_links()
library(usethis)
use_package("MASS")
use_package("MASS")
use_package("mvtnorm")
use_package("stats")
use_package("glmnet")
use_package("randomForest")
use_package("xgboost")
use_package("naivebayes")
devtools::document("TUBE")
devtools::document("../TUBE")
rm(list = c("classify_base", "gen_data", "stratification", "TUBE", "TUBEc"))
devtools::document("../TUBE")
library(naivebayes)
naivebayes::predict.naive_bayes
naivebayes::predict
predict.naive_bayes
predict.naive_bayes
predict.randomForest
devtools::document("../TUBE")
library(devtools)
devtools::document("../TUBE")
devtools::document("../TUBE")
rm(list = ls())
devtools::document("../TUBE")
devtools::document("../TUBE")
devtools::document("../TUBE")
rm(list = ls())
#' "LR" (logistic regression), "penLR" (penalized logistic regression)
#' "RF" (random forest), "GB" (gradient boosting), and "NB" (naive Bayes).
#' @param ... Additional arguments parsed to the algorithms.
#' @return A vector of classification scores for \code{xnew}.
#' @export
#' @import stats
#' @importFrom glmnet glmnet
#' @importFrom randomForest randomForest
#' @importFrom xgboost xgboost xgb.DMatrix
#' @importFrom naivebayes naive_bayes
classify_base = function(xtrain, ytrain, xnew, method, ...){
if(method == "LR"){
dtrain = data.frame(ytrain = ytrain, xtrain)
obj = glm(ytrain~., family=binomial(link='logit'), data = dtrain, ...)
if(is.null(xnew)){
prob = predict(obj, type = "response")
}else{
prob = predict(obj, data.frame(xnew), type = "response")
}
}
if(method == "penLR"){
obj = glmnet(x = xtrain, y = ytrain, family = "binomial",
alpha = 1, ...)
if(is.null(xnew)){
prob = predict(obj, type = "response", s = obj$lambda)
}else{
prob = predict(obj, newx = xnew, type = "response", s = obj$lambda)
}
prob = as.numeric(prob[, 1])
}
if(method == "RF"){
obj = randomForest(x = xtrain, y = factor(ytrain), ...)
if(is.null(xnew)){
prob = predict(obj, type = "prob")[, "1"]
}else{
prob = predict(obj, newdata = xnew, type = "prob")[, "1"]
}
}
if(method == "GB"){
dtrain = xgb.DMatrix(data = xtrain, label = ytrain)
obj = xgboost(data = dtrain, nthread = 1, nrounds = 2,
objective = "binary:logistic", verbose = 0, ...)
if(is.null(xnew)){
prob = predict(obj)
}else{
prob = predict(obj, xnew)
}
}
if(method == "NB"){
colnames(xtrain) = colnames(xnew) = paste0("V", 1:ncol(xtrain))
obj = naive_bayes(x = xtrain, y = as.character(ytrain))
if(is.null(xnew)){
prob = predict(obj, type = "prob")[,"1"]
}else{
prob = predict(obj, xnew, type = "prob")[,"1"]
}
}
return(prob)
}
devtools::document("../TUBE")
library(devtools)
devtools::document("../TUBE")
devtools::document("../TUBE")
devtools::document("../TUBE")
